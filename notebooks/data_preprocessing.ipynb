{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "german-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "import json\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "expanded-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"../data/raw/train.tsv\"\n",
    "VAL_PATH = \"../data/raw/valid.tsv\"\n",
    "TEST_PATH = \"../data/raw/test.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gothic-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datapoints(datapath: str) -> List[Dict]:\n",
    "    with open(datapath) as f:\n",
    "        reader = csv.DictReader(f, delimiter=\"\\t\", fieldnames=[\n",
    "            \"statement_json\",\n",
    "            \"label\",\n",
    "            \"statement\",\n",
    "            \"subject\",\n",
    "            \"speaker\",\n",
    "            \"speaker_title\",\n",
    "            \"state_info\",\n",
    "            \"party_affiliation\",\n",
    "            \"barely_true_count\",\n",
    "            \"false_count\",\n",
    "            \"half_true_count\",\n",
    "            \"mostly_true_count\",\n",
    "            \"pants_fire_count\",\n",
    "            \"context\",\n",
    "            \"justification\"\n",
    "        ])\n",
    "        return [row for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sought-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datum(BaseModel):\n",
    "    statement_json: Optional[str]\n",
    "    label: Optional[bool]\n",
    "    statement: str\n",
    "    subject: Optional[str]\n",
    "    speaker: Optional[str]\n",
    "    speaker_title: Optional[str]\n",
    "    state_info: Optional[str]\n",
    "    party_affiliation: Optional[str]\n",
    "    barely_true_count: float\n",
    "    false_count: float\n",
    "    half_true_count: float\n",
    "    mostly_true_count: float\n",
    "    pants_fire_count: float\n",
    "    context: Optional[str]\n",
    "    justification: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "going-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_data(datapath: str) -> List[Datum]:\n",
    "    with open(datapath) as f:\n",
    "        data = json.load(f)\n",
    "        return [Datum(**point) for point in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "previous-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_clean_counts(data):\n",
    "    normalized_data = []\n",
    "    for index, datum in enumerate(data):\n",
    "        normalized_datum = deepcopy(datum) #  preserve immutability of input data\n",
    "        for count_col in [\"barely_true_count\",\n",
    "                          \"false_count\",\n",
    "                          \"half_true_count\",\n",
    "                          \"mostly_true_count\",\n",
    "                          \"pants_fire_count\"]:\n",
    "            # First check if that this Datum has that particular column. Can allow use of future data which does not have these columns.\n",
    "            if count_col in normalized_datum:\n",
    "                # Cannot pass Nonetype values to float(). If NaN entry we set this to 0\n",
    "                if normalized_datum[count_col] == None:\n",
    "                    normalized_datum[count_col] = float(0)\n",
    "                # Otherwise set the string entry to be floating type\n",
    "                normalized_datum[count_col] = float(normalized_datum[count_col])\n",
    "        # Add this normalized datum (Dict) to the normalized data array\n",
    "        normalized_data.append(normalized_datum)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "documented-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_clean_speaker_title(data: List[Dict]) -> List[Dict]:\n",
    "    normalized_data = []\n",
    "    for datum in data:\n",
    "        # First do simple cleaning\n",
    "        normalized_datum = deepcopy(datum) # preserve immutability of input data\n",
    "        old_speaker_title = normalized_datum[\"speaker_title\"]\n",
    "        # We have some NaN values (Nonetype) in dataset, cannot pass that to .lower() method etc. Give them value \"none\"\n",
    "        if old_speaker_title == None:\n",
    "            old_speaker_title = \"Unknown\"\n",
    "        new_speaker_title = old_speaker_title.lower().strip().replace(\"-\", \" \") if old_speaker_title is not None else None\n",
    "        # Then canonicalize\n",
    "        if new_speaker_title in CANONICAL_SPEAKER_TITLES:\n",
    "            new_speaker_title = CANONICAL_SPEAKER_TITLES[new_speaker_title]\n",
    "        normalized_datum[\"speaker_title\"] = new_speaker_title\n",
    "        normalized_data.append(normalized_datum)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "every-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_clean_state_info(data: List[Dict]) -> List[Dict]:\n",
    "    normalized_data = []\n",
    "    for datum in data:\n",
    "        normalized_datum = deepcopy(datum) # preserve immutability of input data\n",
    "        old_state_info = normalized_datum[\"state_info\"]\n",
    "        # We have some NaN values (Nonetype) in dataset, cannot pass that to .lower() method etc. Give them value \"none\"\n",
    "        if old_state_info == None:\n",
    "            old_state_info = \"Unknown\"\n",
    "        new_state_info = old_state_info.lower().strip().replace(\"-\", \" \") if old_state_info is not None else None\n",
    "        # Check to see if this cleaned state_info datum is in our predefined canonical dictionary\n",
    "        if new_state_info in CANONICAL_STATE:\n",
    "            # Set it to its canonical form\n",
    "            new_state_info = CANONICAL_STATE[new_state_info]\n",
    "        # Enter the cleaned state_info into our new normalized datum\n",
    "        normalized_datum[\"state_info\"] = new_state_info\n",
    "        # Add this cleaned datum to the new normalized dataset\n",
    "        normalized_data.append(normalized_datum)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "charming-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_datapoints(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "passive-houston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'statement_json': '2635.json',\n",
       " 'label': 'false',\n",
       " 'statement': 'Says the Annies List political group supports third-trimester abortions on demand.',\n",
       " 'subject': 'abortion',\n",
       " 'speaker': 'dwayne-bohac',\n",
       " 'speaker_title': 'State representative',\n",
       " 'state_info': 'Texas',\n",
       " 'party_affiliation': 'republican',\n",
       " 'barely_true_count': '0',\n",
       " 'false_count': '1',\n",
       " 'half_true_count': '0',\n",
       " 'mostly_true_count': '0',\n",
       " 'pants_fire_count': '0',\n",
       " 'context': 'a mailer',\n",
       " 'justification': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(train_data) # it is a list\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "trained-garbage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[0]['barely_true_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "documentary-journalism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2142\n",
      "9375\n"
     ]
    }
   ],
   "source": [
    "# we are getting two None's in our train_data somewhere. \n",
    "for idx, datum in enumerate(train_data):\n",
    "    if datum['barely_true_count'] == None:\n",
    "        print(idx)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unsigned-palmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'statement_json': '638.json',\n",
       " 'label': 'false',\n",
       " 'statement': 'The fact is that although we have had a president who is opposed to abortion over the last eight years, abortions have not gone down.\\'\\'\\tabortion\\tbarack-obama\\tPresident\\tIllinois\\tdemocrat\\t70\\t71\\t160\\t163\\t9\\ta TV interview with megachurch pastor Rick Warren in Lake Forest, Calif.\\n2724.json\\ttrue\\tMost of the jobs that we lost were lost before the economic policies we put in place had any effect.\\teconomy,job-accomplishments,jobs,stimulus\\tbarack-obama\\tPresident\\tIllinois\\tdemocrat\\t70\\t71\\t160\\t163\\t9\\tan interview on The Daily Show with Jon Stewart\"',\n",
       " 'subject': None,\n",
       " 'speaker': None,\n",
       " 'speaker_title': None,\n",
       " 'state_info': None,\n",
       " 'party_affiliation': None,\n",
       " 'barely_true_count': None,\n",
       " 'false_count': None,\n",
       " 'half_true_count': None,\n",
       " 'mostly_true_count': None,\n",
       " 'pants_fire_count': None,\n",
       " 'context': None,\n",
       " 'justification': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[2142]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "outdoor-guidance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'statement_json': '1626.json',\n",
       " 'label': 'false',\n",
       " 'statement': \"Joe, I keep hearing you every morning talking about the biggest tax increase in history, but you don't mention it's also the biggest tax cut in history.''\\thealth-care,taxes\\trichard-durbin\\tSenator\\tIllinois\\tdemocrat\\t0\\t2\\t1\\t0\\t1\\ta comment on the Morning Joe'' show on MSNBC.\",\n",
       " 'subject': None,\n",
       " 'speaker': None,\n",
       " 'speaker_title': None,\n",
       " 'state_info': None,\n",
       " 'party_affiliation': None,\n",
       " 'barely_true_count': None,\n",
       " 'false_count': None,\n",
       " 'half_true_count': None,\n",
       " 'mostly_true_count': None,\n",
       " 'pants_fire_count': None,\n",
       " 'context': None,\n",
       " 'justification': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[9375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "brilliant-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_counts = normalize_and_clean_counts(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "reliable-thirty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'statement_json': '1626.json',\n",
       " 'label': 'false',\n",
       " 'statement': \"Joe, I keep hearing you every morning talking about the biggest tax increase in history, but you don't mention it's also the biggest tax cut in history.''\\thealth-care,taxes\\trichard-durbin\\tSenator\\tIllinois\\tdemocrat\\t0\\t2\\t1\\t0\\t1\\ta comment on the Morning Joe'' show on MSNBC.\",\n",
       " 'subject': None,\n",
       " 'speaker': None,\n",
       " 'speaker_title': None,\n",
       " 'state_info': None,\n",
       " 'party_affiliation': None,\n",
       " 'barely_true_count': 0.0,\n",
       " 'false_count': 0.0,\n",
       " 'half_true_count': 0.0,\n",
       " 'mostly_true_count': 0.0,\n",
       " 'pants_fire_count': 0.0,\n",
       " 'context': None,\n",
       " 'justification': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data_counts[9375]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-motion",
   "metadata": {},
   "source": [
    "We can see there are still None entries for the other columns like subject, speaker, context, justification.\n",
    "I handle the party_affliation and speaker_title, state_info etc. but still need to clean subject and speaker, can't have any NaN values passed to the model. Sklearn does not like. \n",
    "Probably can just delete justification. Not context though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "empty-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_justification_col(data: List[Dict]) -> List[Dict]:\n",
    "    normalized_data = []\n",
    "    for datum in data:\n",
    "        normalized_datum = deepcopy(datum) # preserve immutability of input data\n",
    "        if 'justification' in normalized_datum:\n",
    "            del normalized_datum['justification']\n",
    "        normalized_data.append(normalized_datum)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "heavy-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_just = remove_justification_col(cleaned_data_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "transsexual-summer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'statement_json': '1626.json',\n",
       " 'label': 'false',\n",
       " 'statement': \"Joe, I keep hearing you every morning talking about the biggest tax increase in history, but you don't mention it's also the biggest tax cut in history.''\\thealth-care,taxes\\trichard-durbin\\tSenator\\tIllinois\\tdemocrat\\t0\\t2\\t1\\t0\\t1\\ta comment on the Morning Joe'' show on MSNBC.\",\n",
       " 'subject': None,\n",
       " 'speaker': None,\n",
       " 'speaker_title': None,\n",
       " 'state_info': None,\n",
       " 'party_affiliation': None,\n",
       " 'barely_true_count': 0.0,\n",
       " 'false_count': 0.0,\n",
       " 'half_true_count': 0.0,\n",
       " 'mostly_true_count': 0.0,\n",
       " 'pants_fire_count': 0.0,\n",
       " 'context': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_just[9375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "described-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_clean_context(data: List[Dict]) -> List[Dict]:\n",
    "    normalized_data = []\n",
    "    for datum in data:\n",
    "        normalized_datum = deepcopy(datum)\n",
    "        old_context = normalized_datum['context']\n",
    "        if old_context == None:\n",
    "            old_context = \"Unknown\"\n",
    "        new_context = old_context.lower().strip().replace(\"-\", \" \")\n",
    "        normalized_datum[\"context\"] = new_context\n",
    "        normalized_data.append(normalized_datum)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "inappropriate-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1545\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "#string_testing_for = 'news' # 697\n",
    "#string_testing_for = 'speech' #1062\n",
    "# string_testing_for = 'TV ad' #310\n",
    "string_testing_for = 'ad'\n",
    "\n",
    "for datum in train_data:\n",
    "    if datum['context']!= None and string_testing_for in datum['context']:\n",
    "        total += 1\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "practical-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_context = normalize_and_clean_context(cleaned_just)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acting-parish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'statement_json': '1626.json',\n",
       " 'label': 'false',\n",
       " 'statement': \"Joe, I keep hearing you every morning talking about the biggest tax increase in history, but you don't mention it's also the biggest tax cut in history.''\\thealth-care,taxes\\trichard-durbin\\tSenator\\tIllinois\\tdemocrat\\t0\\t2\\t1\\t0\\t1\\ta comment on the Morning Joe'' show on MSNBC.\",\n",
       " 'subject': None,\n",
       " 'speaker': None,\n",
       " 'speaker_title': None,\n",
       " 'state_info': None,\n",
       " 'party_affiliation': None,\n",
       " 'barely_true_count': 0.0,\n",
       " 'false_count': 0.0,\n",
       " 'half_true_count': 0.0,\n",
       " 'mostly_true_count': 0.0,\n",
       " 'pants_fire_count': 0.0,\n",
       " 'context': 'unknown'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_context[9375]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-renaissance",
   "metadata": {},
   "source": [
    "There are only two NaN values for speaker and subject we need to get rid of. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-burner",
   "metadata": {},
   "source": [
    "Will put all of these functions into a python script and run sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-argument",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
